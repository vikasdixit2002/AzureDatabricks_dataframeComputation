{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83a5b318-568f-4253-bb34-e232d84889bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  spark.conf.get(\"spark.sql.session.timeZone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0092baa-846f-42d1-963d-8873668e0150",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "\n",
    "df = spark.read.format(\"json\")\\\n",
    "            .load(\"/databricks-datasets/iot-stream/data-device/part-00000.json.gz\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "#Changing String to Date\n",
    "df1 = df.select(sf.to_date( sf.col(\"timestamP\") ).alias(\"date\"))\n",
    "df1.printSchema()\n",
    "\n",
    "#Changing String to Date\n",
    "df2 = df.select(sf.to_timestamp( sf.col(\"timestamP\") ).alias(\"TimeStamp\"))\n",
    "df2.printSchema()\n",
    "\n",
    "#Changing Date Format\n",
    "df3 = df2.select(\"*\" ,sf.date_format(df2.TimeStamp,\"d/M/y\").alias(\"Newdateformat\"))\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0e3c232-36ac-4ca0-b374-4dbb77c3965b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "import pyspark.sql.types as st\n",
    "\n",
    "#Complex Type and Array\n",
    "userschema = st.StructType([\n",
    "                    st.StructField(\"FirstName\",st.StringType(),True),\n",
    "                    st.StructField(\"ID\",st.LongType(),True),\n",
    "                    st.StructField(\"LastName\",st.StringType(),True),\n",
    "                    st.StructField(\"Skills\",st.ArrayType(st.StructType([\n",
    "                                                        st.StructField(\"Skill\",st.StringType(),True),\n",
    "                                                        st.StructField(\"YearsOfExperience\",st.StringType(),True)\n",
    "                                                        ]))),\n",
    "                    st.StructField(\"Address\",st.StructType([\n",
    "                                                        st.StructField(\"AddressLine1\",st.StringType(),True),\n",
    "                                                        st.StructField(\"AddressLine2\",st.StringType(),True),\n",
    "                                                        st.StructField(\"City\",st.StringType(),True),\n",
    "                                                        st.StructField(\"Country\",st.StringType(),True)\n",
    "                                                        ]))\n",
    "                                   ])\n",
    "\n",
    "df = spark.read.format(\"json\")\\\n",
    "                .schema(userschema)\\\n",
    "               .load(\"/FileStore/tables/test.txt\")\n",
    "df_person =  df.select(df.ID,df.FirstName,df.LastName)\n",
    "\n",
    "df_person_address =  df.select(df.ID,\"Address.*\")\n",
    "\n",
    "df_ps=  df.select(df.ID,sf.explode(df.Skills).alias(\"Skills\"))\n",
    "\n",
    "df_person_skills =  df_ps.select(\"ID\",\"Skills.*\").where(\"Skill == 'SQL'\")\n",
    "\n",
    "\n",
    "display(df_person_skills)\n",
    "display(df)\n",
    "\n",
    "display(df_person)\n",
    "display(df_person_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f095f1be-6d10-4f32-a5e3-f639a19a21f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "import pyspark.sql.types as st\n",
    "\n",
    "#Without Map type\n",
    "userschema = st.StructType([\n",
    "                    st.StructField(\"FirstName\",st.StringType(),True),\n",
    "                    st.StructField(\"ID\",st.StringType(),True),\n",
    "                    st.StructField(\"LastName\",st.StringType(),True),\n",
    "                    st.StructField(\"Skills\",st.ArrayType(st.StructType([\n",
    "                                                        st.StructField(\"Skill\",st.StringType(),True),\n",
    "                                                        st.StructField(\"YearsOfExperience\",st.StringType(),True)\n",
    "                                                        ]))),\n",
    "                    st.StructField(\"Address\",st.StructType([\n",
    "                                                        st.StructField(\"AddressLine1\",st.StringType(),True),\n",
    "                                                        st.StructField(\"AddressLine2\",st.StringType(),True),\n",
    "                                                        st.StructField(\"City\",st.StringType(),True),\n",
    "                                                        st.StructField(\"Country\",st.StringType(),True)\n",
    "                                                        ])),\n",
    "                     st.StructField(\"Contacts\",st.StructType([\n",
    "                                                        st.StructField(\"email\",st.StringType(),True),\n",
    "                                                        st.StructField(\"office\",st.StringType(),True),\n",
    "                                                        st.StructField(\"phone\",st.StringType(),True),\n",
    "                                                        st.StructField(\"whatsapp\",st.StringType(),True)\n",
    "                                                        ]))\n",
    "                                   ])\n",
    "\n",
    "df = spark.read.format(\"json\")\\\n",
    "               .schema(userschema)\\\n",
    "               .load(\"/FileStore/tables/map_type_records.json\")\n",
    "\n",
    "df_contacts = df.select(df.ID,\"Contacts.*\")\n",
    "display(df_contacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf983ec6-997e-41b8-bdd0-a1d7c8be4c9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "import pyspark.sql.types as st\n",
    "\n",
    "#Without Map type\n",
    "userschema = st.StructType([\n",
    "                    st.StructField(\"FirstName\",st.StringType(),True),\n",
    "                    st.StructField(\"ID\",st.StringType(),True),\n",
    "                    st.StructField(\"LastName\",st.StringType(),True),\n",
    "                    st.StructField(\"Skills\",st.ArrayType(st.StructType([\n",
    "                                                        st.StructField(\"Skill\",st.StringType(),True),\n",
    "                                                        st.StructField(\"YearsOfExperience\",st.StringType(),True)\n",
    "                                                        ]))),\n",
    "                    st.StructField(\"Address\",st.StructType([\n",
    "                                                        st.StructField(\"AddressLine1\",st.StringType(),True),\n",
    "                                                        st.StructField(\"AddressLine2\",st.StringType(),True),\n",
    "                                                        st.StructField(\"City\",st.StringType(),True),\n",
    "                                                        st.StructField(\"Country\",st.StringType(),True)\n",
    "                                                        ])),\n",
    "                     st.StructField(\"Contacts\",st.MapType(st.StringType(),st.StringType(),True))\n",
    "                                   ])\n",
    "\n",
    "df = spark.read.format(\"json\")\\\n",
    "               .schema(userschema)\\\n",
    "               .load(\"/FileStore/tables/map_type_records.json\")\n",
    "\n",
    "df1 = df.select(df.ID,sf.explode(\"Contacts\"))\n",
    "\n",
    "df2 = df.select(df.ID,df.Contacts.getItem(\"phone\")\n",
    "                     ,df.Contacts.getItem(\"email\")\n",
    "                     ,df.Contacts.getItem(\"office\")\n",
    "                     ,df.Contacts.getItem(\"whatsapp\"))\n",
    "\n",
    "df2 = df.select(df.ID,df.Contacts[\"phone\"]\n",
    "                     ,df.Contacts[\"email\"]\n",
    "                     ,df.Contacts[\"office\"]\n",
    "                     ,df.Contacts[\"whatsapp\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daa6b83d-c0e3-4195-8b43-b423cd320187",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.head(\"/databricks-datasets/iot-stream/data-device/part-00001.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a29353f8-8a4e-4987-92c3-86b1a951afec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/databricks-datasets/flights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae24c767-8f76-4d98-a7d6-e51e96a14481",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10.Data Type- Date, Struct, Array, Map",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
